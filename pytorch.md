> # PYTORCH


## PYTORCHë€?
- 2017ë…„ ì´ˆ, ê³µê°œëœ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¡œ ë£¨ì•„ì–¸ì–´ë¡œ ê°œë°œë˜ì—ˆë˜ í† ì¹˜ë¥¼ í˜ì´ìŠ¤ë¶ì—ì„œ íŒŒì´ì¬ ë²„ì „ìœ¼ë¡œ ë‚´ë†“ì€ ê²ƒ

- ê°„ê²°í•˜ê³  ë¹ ë¥¸ êµ¬ì„±ìœ¼ë¡œ ì£¼ëª©ë°›ê³  ìˆë‹¤.

## Pytorchì˜ ë™ì  ì‹ ê²½ë§
- í›ˆë ¨ì„ ë°˜ë³µí•  ë•Œë§ˆë‹¤ ë„¤íŠ¸ì›Œí¬ ë³€ê²½ì´ ê°€ëŠ¥í•œ ì‹ ê²½ë§ì„ ì˜ë¯¸
- ì˜ˆë¥¼ ë“¤ì–´ í•™ìŠµì¤‘ì— ì€ë‹‰ì¸µ ì¶”ê°€ë‚˜ ì œê±°ë“± ëª¨ë¸ì˜ ë„¤íŠ¸ì›Œí¬ ì¡°ì‘ì´ ê°€ëŠ¥í•˜ë‹¤.
- ì—°ì‚°ê·¸ë˜í”„ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒê³¼ ë™ì‹œì— ê°’ë„ ì´ˆê¸°í™”ê°€ ë™ì‹œì— ë˜ëŠ” **Defin by Run**ë°©ì‹ì„ ì‚¬ìš© ë”°ë¼ì„œ ì—°ì‚°ê·¸ë˜í”„ì™€ ì—°ì‚°ì„ ë¶„ë¦¬í•´ì„œ ìƒê°í•  í•„ìš”ê°€ ì—†ì–´ ì½”ë“œì´í•´ê°€ ì‰½ë‹¤.
- ì´ì— ë°˜í•´ TensorflowëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ê³  ê°’ì„ ë”°ë¡œ ë„£ì–´ì£¼ëŠ” **Define and Run** ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤.

![define by and run](./img_1/%EC%BA%A1%EC%B2%982.PNG)

## pytorchì˜ êµ¬ì„±ìš”ì†Œ
1. torch: GPUë¥¼ ì§€ì›í•˜ëŠ” í…ì„œ íŒ¨í‚¤ì§€

2. torch.autograd: ìë™ ë¯¸ë¶„ íŒ¨í‚¤ì§€

3. torch.nn: ì‹ ê²½ë§ êµ¬ì¶• ë° í›ˆë ¨ íŒ¨í‚¤ì§€(ë°ì´í„° êµ¬ì¡°ë‚˜ ë ˆì´ì–´ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬)

4. torch.multiprocessing: íŒŒì´ì¬ ë©€í‹°í”„ë¡œì„¸ì‹± íŒ¨í‚¤ì§€

5. torch.optim: SGDë¥¼ ì¤‘ì‹¬ìœ¼ë¡œí•œ íŒŒë¼ë¯¸í„° ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì œê³µ

6. torch.utils: DataLoaderë° ë°ì´í„° ì¡°ì‘ë“± ê¸°íƒ€ ìœ í‹¸ë¦¬í‹° ê¸°ëŠ¥ì„ ì œê³µ

7. torch.onnx: ONNX(Open Neural Network Exchange). ì„œë¡œ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ ê°„ì˜ ëª¨ë¸ì„ ê³µìœ í•  ë•Œ ì‚¬ìš©

## Pytorch vs tensorflow
- ### ëª¨ë“ˆì˜ ì°¨ì´
![ë¹„êµ](./img_1/%EC%BA%A1%EC%B2%983.PNG)

- ### ë ˆì´ì–´ì˜ ì°¨ì´
![ë ˆì´ì–´](./img_1/%EC%BA%A1%EC%B2%984.PNG)

- ### í›ˆë ¨ë°©ì‹ì˜ ì°¨ì´
![íŠ¸ë ˆì¸1](./img_1/%EC%BA%A1%EC%B2%985.PNG)

![íŠ¸ë ˆì¸2](./img_1/%EC%BA%A1%EC%B2%986.PNG)

>> # PYTORCH ì½”ë“œ êµ¬í˜„

## 1.torch.Tensorì™€ torch.tensor

```python
- "torch.Tensor"
    - í´ë˜ìŠ¤ (Class)
    - int ì…ë ¥ì‹œ floatë¡œ ë³€í™˜
    - torch ë°ì´í„° ì…ë ¥ì‹œ ì…ë ¥ ë°›ì€ ë°ì´í„°ì˜ ë©”ëª¨ë¦¬ ê³µê°„ì„ ì‚¬ìš©
    - list, numpy ë°ì´í„° ì…ë ¥ ì‹œ ì…ë ¥ ë°›ì€ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ì—¬
      ìƒˆë¡­ê²Œ torch.Tensorë¥¼ ë§Œë“  í›„ ì‚¬ìš©
- "torch.tensor"
    - í•¨ìˆ˜ (Function)
    - int ì…ë ¥ì‹œ int ê·¸ëŒ€ë¡œ ì…ë ¥
    - ì…ë ¥ ë°›ì€ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ ê³µê°„ìœ¼ë¡œ ë³µì‚¬ í›„ ì‚¬ìš©

ì§¤ë§‰í•œ TIP
Class : ì•ê¸€ìê°€ ëŒ€ë¬¸ìë¡œ ì‹œì‘

Function: ì•ê¸€ìê°€ ì†Œë¬¸ìë¡œ ì‹œì‘
```

- **ì¤‘ìš”í•œ Point**: torch.TensorëŠ” torchê°’ì´ ë“¤ì–´ì˜¬ë•ŒëŠ” ë©”ëª¨ë¦¬ ê³µê°„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì›ë³¸ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ë©´ ìˆ˜ì •ê°’ì´ ë‹¤ë¥¸ ì‘ì—…ì—ë„ ì˜í–¥ì„ ë¯¸ì¹¨

- torch.tensorì˜ ê²½ìš° ì• ì´ˆì— ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì›ë³¸ë°ì´í„°ë¥¼ ìˆ˜ì •í•´ë„ ë‹¤ë¥¸ ì‘ì—…ì— ì˜í–¥ì„ ì£¼ì§€ì•ŠìŒ

- torch.Tensorì˜ ê²½ìš°ë¼ê³  í•˜ë”ë¼ë„ listë‚˜ numpyìë£Œí˜•ì˜ ê²½ìš° ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ì‘ì—…ì— ì˜í–¥ì„ ë¼ì¹˜ì§€ì•ŠìŒ


## 2. PYTORCHì˜ ì—°ì‚°
- torch.add : ë”í•˜ê¸°
- torch.sub : ë¹¼ê¸°
- torch.mul : ê³±í•˜ê¸°
- torch.div : ë‚˜ëˆ„ê¸°

```python
Quiz: ((4*2)-(1+2)) - 5 ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”!

A = torch.Tensor([4])
B = torch.Tensor([2])
C = torch.Tensor([1])
D = torch.Tensor([2])
E = torch.Tensor([5])

# 1ì¤„ì— torchí•¨ìˆ˜ í•˜ë‚˜ì”©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!
out1 = torch.mul(A,B)
out2 = torch.add(C,D)
out3 = torch.sub(out1,out2)

output = torch.sub(out3,E)

print("result = {}".format(output))
```

- torch.mm ,torch.matmul: ë‚´ì ê³±ì„ ìˆ˜í–‰í•  ë–„, í™œìš©í•  ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ matmulì€ broadcastê°€ ì§€ì›ì´ ëœë‹¤.

```python
# (3, 2) í¬ê¸°ì˜ X í…ì„œì™€ (2, 2) í¬ê¸°ì˜ Y í…ì„œë¥¼ ìƒì„±í•œë‹¤.
X = torch.Tensor([[1, 4], 
                  [2, 5], 
                  [3, 6]])

Y = torch.Tensor([[7, 9], 
                  [8, 10]])

# í–‰ë ¬ì˜ ê³±ì…ˆì„ í•œë‹¤.
print(torch.mm(X, Y)) # ë¸Œë¡œë“œìºìŠ¤íŒ…ì„ ì§€ì›í•˜ì§€ì•ŠëŠ”ë‹¤ 
print()
print(X.mm(Y))

```

-  max & argmax / min & argmin: ìµœëŒ“ê°’,ìµœì†Ÿê°’ í¬ê¸° ë° ìœ„ì¹˜ êµ¬í•˜ê¸°.

```python

# í…ì„œì˜ ëª¨ë“  ì›ì†Œì¤‘ ìµœëŒ€ê°’ ë° ìµœëŒ€ê°’ì˜ ìœ„ì¹˜ êµ¬í•˜ê¸°
print("Z max:", torch.max(Z))
print("Z argmax:", torch.argmax(Z))

# í…ì„œì˜ ëª¨ë“  ì›ì†Œì¤‘ ìµœì†Œê°’ ë° ìµœì†Œê°’ì˜ ìœ„ì¹˜ êµ¬í•˜ê¸°
print("Z min:", torch.min(Z))
print("Z argmin:", torch.argmin(Z))

# ì°¨ì› ì§€ì •ì‹œ ì§€ì •ëœ ì°¨ì›ì„ ê¸°ì¤€ìœ¼ë¡œ ì°¨ì›ì´ ì¶•ì†Œë˜ë©°, ìµœëŒ€ê°’ ë° ìœ„ì¹˜ í˜¹ì€ ìµœì†Œê°’ ë° ìœ„ì¹˜ë¥¼ íŠœí”Œë¡œ ë°˜í™˜í•œë‹¤.

Z_max, Z_argmax = torch.max(Z, dim=1)
Z_min, Z_argmin = torch.min(Z, dim=1)
print("Z max:\n", Z_max)
print("Z argmax:\n", Z_argmax)
print()
print("Z min:\n", Z_min)
print("Z argmin:\n", Z_argmin)

```



## 3. í…ì„œë¡œì˜ ë³€í™˜ ë° ë˜ëŒì•„ê°€ê¸°
  ```python
  # list ë¡œë¶€í„° 2x3 í…ì„œ ìƒì„±
x_list = [[1, 2, 3], [4, 5, 6]]
x = torch.Tensor(x_list)
print(x)

# numpy array ë¡œë¶€í„° 2x3 í…ì„œ ìƒì„±
x_numpy = np.array([[1, 2, 3], [4, 5, 6]])
x = torch.Tensor(x_numpy) # floatí˜•ìœ¼ë¡œ ì¶œë ¥
print(x)
print(type(x))

----- í…ì„œë³€í™˜ ------


# .tolist()
x_back2list = x.tolist() # ê°™ì€ level(ìœ„ì¹˜)ì— ìˆëŠ” ë°ì´í„°ë¼ë¦¬ ë¬¶ì–´ì¤€ë‹¤.
print(type(x_back2list))

# .numpy()
x_back2numpy = x.numpy()
print(type(x_back2numpy))

---- ë‹¤ì‹œ ì›ë˜ í˜•íƒœë¡œ ë³µê·€ ------

```

## 4. Pytorch GPUì‚¬ìš©
- pytorchì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ device ì •ë³´ë¥¼ í…ì„œì— **'string'**íƒ€ì…ìœ¼ë¡œ ì „ë‹¬í•´ì¤˜ì•¼ í•œë‹¤
- 'cuda':GPUì‚¬ìš©
- 'cpu':CPUì‚¬ìš©

```python
#@title
# ê¸°ë³¸ device ì •ë³´
print("í…ì„œ x ì˜ device:", x.device) # cpu

device = 'cuda'
# GPU ì‚¬ìš©
x = x.to(device)
print("device ì •ë³´ ì „ë‹¬ í›„, í…ì„œ x ì˜ device:", x.device)

device = 'cpu'
# CPU ì‚¬ìš©
x = x.to(device)
print("device ì •ë³´ ì „ë‹¬ í›„, í…ì„œ x ì˜ device:", x.device)
```


## 5. ëœë¤ í…ì„œ ìƒì„±í•˜ê¸°
- torch.manual_seed: ë™ì¼í•œ ê²°ê³¼ë¥¼ ë§Œë“¤ë„ë¡ seedê³ ì •

- torch.rand:[0,1]ì‚¬ì´ì˜ ëœë¤ í…ì„œ ìƒì„±

- torch.randn: í‰ê· =0, í‘œì¤€í¸ì°¨=1ì¸ ì •ê·œë¶„í¬ë¡œë¶€í„° ëœë¤ í…ì„œ ìƒì„±

- torch.randint: [ìµœì €ê°’(low),ìµœëŒ€ê°’(high),í˜•íƒœ(size)] ì‚¬ì´ì—ì„œ ëœë¤ ì •ìˆ˜ í…ì„œ ìƒì„±

ì¶”ê°€ì ìœ¼ë¡œ

- torch.zeros_like : ì…ë ¥ í…ì„œì™€ ê°™ì€ í¬ê¸°,íƒ€ì…,ë””ë°”ì´ìŠ¤ë¡œ 0ìœ¼ë¡œ ì±„ìš´ í…ì„œ ìƒì„±

- torch.ones_like: ì…ë ¥ í…ì„œì™€ ê°™ì€ í¬ê¸°, íƒ€ì…, ë””ë°”ì´ìŠ¤ë¡œ 1ë¡œ ì±„ìš´ í…ì„œ ìƒì„±
```python
torch.manual_seed(777)
# ëœë¤ ìˆ«ìë¡œ êµ¬ì„±ëœ í¬ê¸°ê°€ 2x3 ì¸ í…ì„œ ìƒì„±
# 0ê³¼ 1ì‚¬ì´ì˜ ëœë¤í•œ ìˆ«ì
print("torch.rand\n-------------")
x = torch.rand(2, 3)
print(x)
print()

# í‰ê· =0, í‘œì¤€í¸ì°¨=1 ì •ê·œë¶„í¬ì—ì„œ ìƒì„±
print("torch.randn\n-------------")
x = torch.randn(2, 3)
print(x)
print()

# 0ê³¼ 8 ì‚¬ì´ì˜ ì •ìˆ˜í˜• ëœë¤í•œ ìˆ«ì
print("torch.randint\n-------------")
x = torch.randint(low=0, high=8, size=(2, 3))
print(x)
print()

# GPUë¥¼ ì‚¬ìš©í•˜ê³  í¬ê¸°ê°€ x ì™€ ê°™ì€ 0ìœ¼ë¡œ ì±„ì›Œì§„ í…ì„œ ìƒì„±
x_zeros = torch.zeros_like(x.cuda())
print(x_zeros.device)
print(x_zeros)


Quiz: 0ë¶€í„° 9ì‚¬ì´ì˜ ëœë¤ ì •ìˆ˜ 3 * 4í¬ê¸°ì˜ í–‰ë ¬ì„ ë§Œë“¤ê³ , ë‹¤ë¥¸ í–‰ë ¬ì€ ë””ë°”ì´ìŠ¤ë¡œ 1ë¡œ ì±„ì›Œì§„ ë™ì¼í•œ í¬ê¸°ì˜ í…ì„œë¥¼ ìƒì„±í•œ í›„ ë‘ í–‰ë ¬ì„ ë”í•´ì„œ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”.

A = torch.randint(low=0, high=9, size=(3, 4))
B = torch.ones_like(A)

output =  torch.add(A,B)
print(output)
```

## 6. Tensorì˜ type ì•Œì•„ë³´ê¸°

```python
# ì‹¤ìˆ˜í˜• í…ì„œ
a = torch.FloatTensor(np.array([[1, 2, 3], 
                                [4, 5, 6]]))

# ì •ìˆ˜í˜• í…ì„œ
b = torch.LongTensor(np.array([[1, 2, 3], 
                               [4, 5, 6]]))

# 8 bit ì •ìˆ˜í˜•
c = torch.ByteTensor([True, False, True, True])
---ë°˜í™˜ì‹œ TrueëŠ” 1ë¡œ FalseëŠ” 0ìœ¼ë¡œ í‘œì‹œ---
# ë¶ˆë¦¬ì–¸í˜• í…ì„œ
d = torch.BoolTensor([True, False, True, True])
```

## 7. í…ì„œì˜ ì¡°ì‘ 
- í…ì„œ ì—­ì‹œ ë‹¤ë¥¸ ìë£Œí˜•ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ
ìŠ¬ë¼ì´ì‹±ê³¼ ê°™ì€ ì¡°ì‘ì´ ê°€ëŠ¥í•˜ë‹¤.

- data.flatten()ì„ í†µí•´ ì°¨ì›ì„ ì¶•ì†Œì‹œí‚¬ ìˆ˜ ìˆë‹¤.

```python
ìŠ¬ë¼ì´ì‹± ì˜ˆì‹œ

# ì˜ˆì‹œ í…ì„œ
torch.manual_seed(777)
x = torch.randint(0, 10, size=(2, 3, 4))

xëŠ” (2, 3, 4) í¬ê¸°ë¥¼ ê°€ì§€ëŠ” í…ì„œë‹¤. 

ì²«ë²ˆì§¸ ì°¨ì›ì˜ 0ë²ˆ ì›ì†Œ, ë‘ë²ˆì§¸ ì°¨ì›ì˜ 2ë²ˆ ì›ì†Œ, ì„¸ë²ˆì§¸ ì°¨ì›ì˜ 3ë²ˆ ì›ì†Œë¥¼ ì„ íƒí•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•œë‹¤.

x[0,2,3]

ì¸ë±ì‹±ìœ¼ë¡œ ìƒê°í•˜ì—¬ ê° í¬ê¸°ì˜ n-1ê¹Œì§€ê°€ ìµœëŒ€í¬ê¸°ë¼ê³  ìƒê°í•˜ë©´ ì´í•´ê°€ ì‰¬ì›€

3ì°¨ì› ê¸°ì¤€ìœ¼ë¡œ,

x[]ì•ˆì˜ê°’ì˜ ì²«ë²ˆì§¸ëŠ” ê¹Šì´ 2ë²ˆì§¸ëŠ” ê°€ë¡œ(í–‰)
3ë²ˆì§¸ëŠ” ì„¸ë¡œ(ì—´)ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.

```

- view: í…ì„œ í¬ê¸°ë¥¼ ì•Œë§ê²Œ ë³€í™”í•´ì•¼í•  ë•Œ ìì£¼ ì‚¬ìš©í•œë‹¤. ë³€í™”ë˜ëŠ” ì°¨ì› í¬ê¸°ì˜ ì´ ê³±ì€ ì›ë˜ ì°¨ì›í¬ê¸°ì˜ ì´ ê³±ê³¼ ì¼ì¹˜í•´ì•¼í•œë‹¤.

```python

# í¬ê¸°ê°€ (2, 3, 4) 3ì°¨ì› í…ì„œë¥¼ (2, 2, 6) ìœ¼ë¡œ ë³€ê²½
x_viewed1 = x.view(2,2,6)

# í…ì„œ ì‹œê°í™”
print("original tensor: ", x.size())
mask = torch.ones_like(x)
draw_tensor(mask, x)

print("reshaped tensor: ", x.size())
mask = torch.ones_like(x_viewed1)
draw_tensor(mask, x_viewed1)


# "-1"ì„ ì‚¬ìš©í•˜ë©´ ë‚˜ë¨¸ì§€ ì°¨ì›ì„ ì•Œì•„ì„œ ê³„ì‚° í•´ì¤€ë‹¤. ë‹¨, 2ê³³ ì´ìƒ ë™ì‹œì‚¬ìš©ì€ ë¶ˆê°€ëŠ¥

# í¬ê¸°ê°€ (2, 3, 4) 3ì°¨ì› í…ì„œë¥¼ (2, 1, 12) ìœ¼ë¡œ ë³€ê²½
x_viewed2 = x.view(-1,1,12)
# 1,12 ê³ ì •ë˜ë©´ -1ì´ ìë™ì ìœ¼ë¡œ ì„¤ì •

# í…ì„œ ì‹œê°í™”
print("original tensor: ", x.size())
mask = torch.ones_like(x)
draw_tensor(mask, x)

print("reshaped tensor: ", x_viewed2.size())
mask = torch.ones_like(x_viewed2)
draw_tensor(mask, x_viewed2)

```
- í…ì„œì˜ ì¸ë±ì‹± ì—­ì‹œ ê°€ëŠ¥í•˜ë‹¤(torch.index_select í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥)

```python
A = torch.Tensor([[1, 2],
                  [3, 4]])

# [1, 3]ë§Œ ì¶œë ¥í•´ë´…ì‹œë‹¤.

# torch.index_select í•¨ìˆ˜ë¥¼ ì¨ì„œ í•´ë³´ì„¸ìš”!
output = torch.index_select(A, 1, torch.tensor([0])) #ì…ë ¥í…ì„œ ,axis , index
output = output.view(-1)
output

# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì¸ë±ì‹±ê³¼ ë¹„ìŠ·í•œ ë°©ë²•ìœ¼ë¡œ í•´ë³´ì„¸ìš”!
output = A[:,0]
output
```


- Permute : ì°¨ì›ì˜ ìœ„ì¹˜ë¥¼ ë°”ê¿€ë•Œ, ì£¼ë¡œ ì‚¬ìš©(í…ì„œ ì „ì²´ ëª¨ì–‘ ë°”ê¿€ë•Œ ìœ ìš©)

```python
x = torch.zeros(2,3,4)

# (2, 3, 4) í¬ê¸° í…ì„œì˜ ì°¨ì› í¬ê¸°ë¥¼ (4, 3, 2)ë¡œ ë°”ê¾¼ë‹¤. rank, shape
x_permuted = x.permute(2,1,0)

ì¸ë±ìŠ¤ ìˆœì„œë¡œ ì¬ì •ë ¬ í–ˆë‹¤ê³  ì´í•´í•˜ë©´ í¸í•˜ë‹¤

xì˜ ì¸ë±ìŠ¤ ìœ„ì¹˜ 2ëŠ” :4
xì˜ ì¸ë±ìŠ¤ ìœ„ì¹˜ 1ì€: 3
xì˜ ì¸ë±ìŠ¤ ìœ„ì¹˜ 0ì€ : 2
```

- transpose: permuteì˜ íŠ¹ë³„í•œ ì¼€ì´ìŠ¤ë¡œ ì£¼ë¡œ 2ê°œ ì°¨ì›ì„ êµí™˜í•˜ì—¬ ë°”ê¿€ ë–„, ì‚¬ìš©í•œë‹¤.

```python
# (2, 3, 4) í¬ê¸° í…ì„œì˜ ì²«ë²ˆì§¸ ì°¨ì›ê³¼ ë‘ë²ˆì§¸ ì°¨ì›ì´ ë°”ë€ë‹¤.
x_transposed = x.transpose(1,0)

# í…ì„œ ì‹œê°í™”
print("original tensor: ", x.size())
mask = torch.ones_like(x)
draw_tensor(mask, x)

print("reshaped tensor", x_transposed.size())
mask = torch.ones_like(x_transposed)
draw_tensor(mask, x_transposed)
```

- Squeeze and unsqueeze
  - squeeze: í…ì„œì˜ í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì§€ìš´ë‹¤. ì°¨ì›ì„ íŠ¹ì •í•˜ë©´(ìˆ«ìë¥¼ ì´ìš©í•´ì„œ)ê·¸ ì°¨ì›ì˜ í¬ê¸°ê°€ 1ì´ë©´ ì§€ìš°ê³  ì•„ë‹ˆë©´ ê·¸ëƒ¥ ë‘”ë‹¤.

  - unsqueeze: í•´ë‹¹í•˜ëŠ” ìˆ«ì ì°¨ì›ì— í¬ê¸° 1ì¸ ì°¨ì›ì„ ëŠ˜ë¦°ë‹¤.
  np.newaxisì™€ ë¹„ìŠ·í•œ íš¨ê³¼

```python
# í¬ê¸°ê°€ (2, 1, 3, 4, 1) ì¸ 5ì°¨ì› í…ì„œë¥¼ ìƒì„±í•œë‹¤
x = torch.rand((2, 1, 3, 4, 1))
print(x.size())

# ëª¨ë“  ì°¨ì›ì—ì„œ í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ squeeze í•œë‹¤.
print(x.squeeze().size())  # í¬ê¸°í™•ì¸
torch.Size([2, 3, 4])

# ë‘ë²ˆì§¸ ì°¨ì›(í¬ê¸° = 1)ì„ squeeze í•œë‹¤.
print(x.squeeze(4).size())  # í¬ê¸°í™•ì¸
torch.Size([2, 1, 3, 4])
# 4ë²ˆì§¸ ì°¨ì›ì— í¬ê¸°ë¥¼ 1 ì¶”ê°€, 6ì°¨ì› í…ì„œê°€ ëœë‹¤.
print(x.unsqueeze(4).size())  # í¬ê¸°í™•ì¸
torch.Size([2, 1, 3, 4, 1, 1])
```

- catê³¼ stack
    - catì˜ ê²½ìš° í…ì„œë¥¼ í•©ì¹œë‹¤ëŠ” ëŠë‚Œì´ ê°•í•˜ë‹¤. ì§€ì •í•œ ì°¨ì›ë°©í–¥ì˜ ë‘í…ì„œê°€ ê°™ì•„ì•¼í•œë‹¤.
     
```python
  torch.manual_seed(777)
# í¬ê¸°ê°€ (2, 3) ì¸ A, B í…ì„œë¥¼ ë§Œë“ ë‹¤
A = torch.rand((2, 3))
B = torch.rand((2, 3))

# ì²«ë²ˆì§¸ ì°¨ì›ì„ ê¸°ì¤€ìœ¼ë¡œ í…ì„œë¥¼ concatenate í•œë‹¤.
AB_cated = torch.cat([A, B], dim=0) # dim = 0 ê°€ë¡œê¸°ì¤€ dim = 1 ì„¸ë¡œ ê¸°ì¤€
print(A)
print(B)
print(AB_cated)

```

   - stack: í…ì„œë“¤ì„ ìŒ“ëŠ”ë‹¤ëŠ” ëŠë‚Œì´ ê°•í•˜ë‹¤. ê° ë¦¬ìŠ¤íŠ¸ ì•ˆì— ìˆëŠ” ì§€ì •ëœ ì°¨ì›ì„ unsqueezeí•œ ë‹¤ìŒ, catì„ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.

```python
# ì²«ë²ˆì§¸ ì°¨ì›ì„ ê¸°ì¤€ìœ¼ë¡œ í…ì„œë¥¼ stack í•œë‹¤.
AB_stacked = torch.stack([A, B], dim=0)
print("torch.stack([A, B], dim=0)\n")
print(AB_stacked)
print("----"*10)
print("torch.cat([A.unsqueeze(0), B.unsqueeze(0)], dim=0)\n")
# ê° í…ì„œë¥¼ ì²«ë²ˆì§¸ ì°¨ì› ê¸°ì¤€ìœ¼ë¡œ unsqueeze í›„, cat í•œê²ƒê³¼ ê°™ì€ ê²°ê³¼
AB_unsqueeze_cat = torch.cat([A.unsqueeze(0), B.unsqueeze(0)], dim=0)
print(AB_unsqueeze_cat)

```





>> ## PYTORCH ëª¨ë“ˆ 

### 1. torch.nn
- torch.nn ê³µì‹ë¬¸ì„œ ì½ê¸°[ê³µì‹](https://pytorch.org/docs/stable/nn.html)

### 1-1 nn.linear
- y= wx + bì˜ linear transformationì„ êµ¬í˜„í•´ë†“ì€ ê²ƒ

í™œìš©ì˜ˆì œ(í…ì„œ í¬ê¸° ë³€í™˜)
```python
import torch
from torch import nn

---ëª¨ë“ˆ import ---

X = torch.Tensor([[1, 2],
                  [3, 4]])

# TODO : tensor Xì˜ í¬ê¸°ëŠ” (2, 2)ì…ë‹ˆë‹¤
#        nn.Linearë¥¼ ì‚¬ìš©í•˜ì—¬ì„œ (2, 5)ë¡œ í¬ê¸°ë¥¼ ë°”ê¾¸ê³  ì´ í¬ê¸°ë¥¼ ì¶œë ¥í•˜ì„¸ìš”!

linear = nn.Linear(2,5)
output = linear(X)
output.size()

```
### 1-2 nn.identity
- ì…ì¶œë ¥ê°’ì´ ë™ì¼í•œ í…ì„œë¥¼ ì¶œë ¥í•¨ 

```python
import torch
from torch import nn

X = torch.Tensor([[1, 2],
                  [3, 4]])

# TODO : nn.Identityë¥¼ ìƒì„±í•´ Xë¥¼ ì…ë ¥ì‹œí‚¨ í›„ ë‚˜ì˜¨ ì¶œë ¥ê°’ì´ Xì™€ ë™ì¼í•œì§€ í™•ì¸í•´ë³´ì„¸ìš”!
identity = nn.Identity()
output = identity(X)
output
```
### 1-3. nn.Module í´ë˜ìŠ¤
- ì»¤ìŠ¤í…€ ëª¨ë¸ ì œì‘ì„ ìœ„í•œ í´ë˜ìŠ¤

- pythorchì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ë“¤ì„ ì¡°í•©í•˜ì—¬ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆë„ë¡ ì´ëŸ° ì¼ë ¨ì˜ ê¸°ëŠ¥ë“¤ì„ í•œ ê³³ì— ëª¨ì•„ í•˜ë‚˜ì˜ ëª¨ë°ë¡¤ ì¶”ìƒí™”í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ë‹¤.

- nn.module ìì²´ëŠ” ë¹ˆ ìƒìë¡œ ì´í•´í•  ìˆ˜ ìˆìœ¼ë©° ì–´ë– í•œ ê²ƒì„ ì±„ì›Œë†“ëŠëƒì— ë”°ë¼ ì—­í• ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤. ê·¸ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 

  
  - `nn.Module`ì´ë¼ëŠ” ìƒìì— `ê¸°ëŠ¥`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `basic building block`
  - `nn.Module`ì´ë¼ëŠ” ìƒìì— `basic building block`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”¥ëŸ¬ë‹ ëª¨ë¸`
  - `nn.Module`ì´ë¼ëŠ” ìƒìì— `ë”¥ëŸ¬ë‹ ëª¨ë¸`ì¸ `nn.Module`ë“¤ì„ ê°€ë“ ëª¨ì•„ë†“ì€ ê²½ìš° `ë”ìš± í° ë”¥ëŸ¬ë‹ ëª¨ë¸`

### nn.module ëª¨ë¸ ì œì‘ ì˜ˆì‹œ
- ë”í•˜ê¸° ì—°ì‚°ëª¨ë¸
```python
import torch
from torch import nn

# TODO : Add ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!
class Add(nn.Module):
    def __init__(self):
        # TODO : init ê³¼ì •ì—ì„œ ë°˜ë“œì‹œ super ê´€ë ¨ ì½”ë“œê°€ ë“¤ì–´ê°€ì•¼í•¨
        super().__init__()

    def forward(self, x1, x2):
        # TODO : torch.add í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë”í•˜ê¸° ì—°ì‚° êµ¬í˜„
        output = torch.add(x1, x2)

        return output



x1 = torch.tensor([1])
x2 = torch.tensor([2])

add = Add() # í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° 
output = add(x1, x2)

output #3
```
Q.ì–´ì§¸ì„œ ì‚¬ìš©ì ì§€ì • í´ë˜ìŠ¤ ì‘ì„±ì‹œ super ê´€ë ¨ ì½”ë“œê°€ ë“¤ì–´ê°€ì•¼í•˜ë‚˜ìš”? 

A: python í™˜ê²½ì—ì„œ  ìƒìœ„ í´ë˜ìŠ¤ ìƒì„±ì í˜¹ì€ ì´ˆê¸°í™”ìëŠ” ìë™ìœ¼ë¡œ í˜¸ì¶œ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 
ë”°ë¼ì„œ nn.module class ìì²´ê°€ ì´ˆê¸°í™” ë˜ë„ë¡ superí˜¸ì¶œì´ í•„ìš”í•©ë‹ˆë‹¤.

python 3ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, super()í˜¸ì¶œì— ì¸ìê°€ ë”°ë¡œ í•„ìš”í•˜ì§€ ì•Šê³  ë‹¨ìˆœíˆ super().__init__()ìœ¼ë¡œ ì¡±í•©ë‹ˆë‹¤.

- torch.sequential: ëª¨ë“ˆë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©
   - ë¬¶ì–´ë†“ì€ ëª¨ë“ˆì„ ì°¨ë¡€ëŒ€ë¡œ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ì‹¤í–‰ìˆœì„œê°€ ì •í•´ì ¸ìˆëŠ” ê¸°ëŠ¥ë“¤ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ë†“ê¸°ê°€ ì¢‹ë‹¤.
  
```python
import torch
from torch import nn

# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!
class Add(nn.Module):
    def __init__(self, value):
        super().__init__()
        self.value = value

    def forward(self, x):
        return x + self.value

# TODO : ìœ„ì— ëª¨ë“ˆ(Module)ê³¼ nn.Sequentialë¥¼ ì´ìš©í•´ì„œ
#        ì…ë ¥ê°’ xê°€ ì£¼ì–´ì§€ë©´ ë‹¤ìŒì˜ ì—°ì‚°ì„ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!
#        y = x + 3 + 2 + 5
calculator = nn.Sequential(Add(3),
                           Add(2),
                           Add(5))


# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
x = torch.tensor([1])

output = calculator(x)

output # 11
```

- nn.modulelist(): pythonì˜ ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ëª¨ë“ˆë“¤ì„ ëª¨ì•„ë‘ê³  ê·¸ë•Œê·¸ë•Œ ì›í•˜ëŠ” ê²ƒë§Œ indexingí•´ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ì€ ê²½ìš° ì´ê²ƒì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

```python 
import torch
from torch import nn

# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!
class Add(nn.Module):
    def __init__(self, value):
        super().__init__()
        self.value = value

    def forward(self, x):
        return x + self.value


# TODO : Calculator ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!
class Calculator(nn.Module):
    def __init__(self):
        super().__init__()
        self.add_list = nn.ModuleList([Add(2), Add(3), Add(5)])

    def forward(self, x):
        # TODO : self.add_listì— ë‹´ê¸´ ëª¨ë“ˆë“¤ì„ ì´ìš©í•˜ì—¬ì„œ
        #        y = ((x + 3) + 2) + 5 ì˜ ì—°ì‚°ì„ êµ¬í˜„í•˜ì„¸ìš”!

        x = self.add_list[1](x)  # ìœ„ì—ì„œ modulelistì— ë‹´ê¸´ ëª¨ë“ˆaddë¥¼ ì¸ë±ì‹±ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ê³  ìˆë‹¤.
        x = self.add_list[0](x)
        x = self.add_list[2](x)
        
        return x


# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
x = torch.tensor([1])

calculator = Calculator()
output = calculator(x)

output # 11
```

- torch.nn.ModuleDict
  - íŒŒì´ì¬ì˜ dictì²˜ëŸ¼ íŠ¹ì • ëª¨ë“ˆì„ keyê°’ì„ ì´ìš©í•´ ë³´ê´€í•´ë†“ì„ ìˆ˜ ìˆë‹¤.

```python
import torch
from torch import nn

# TODO : ë‹¤ìŒì˜ ëª¨ë“ˆ(Module)ì„ ì½ê³  ì´í•´í•´ë³´ì„¸ìš”!
class Add(nn.Module):
    def __init__(self, value):
        super().__init__()
        self.value = value

    def forward(self, x):
        return x + self.value


# TODO : Calculator ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!
class Calculator(nn.Module):
    def __init__(self):
        super().__init__()
        self.add_dict = nn.ModuleDict({'add2': Add(2),
                                       'add3': Add(3),
                                       'add5': Add(5)})

    def forward(self, x):
        # TODO : self.add_dictì— ë‹´ê¸´ ëª¨ë“ˆë“¤ì„ ì´ìš©í•˜ì—¬ì„œ
        #        y = ((x + 3) + 2) + 5 ì˜ ì—°ì‚°ì„ êµ¬í˜„í•˜ì„¸ìš”!

        x = self.add_dict['add3'](x)
        x = self.add_dict['add2'](x)
        x = self.add_dict['add5'](x)
        
        return x


# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
x = torch.tensor([1])

calculator = Calculator()
output = calculator(x)

output # 11
```

- torch.parameter êµ¬í˜„
```python
import torch
from torch import nn
from torch.nn.parameter import Parameter


# TODO : Linear ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!
class Linear(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()

        # TODO : W, b parameterë¥¼ ìƒì„±í•˜ì„¸ìš”! ëª¨ë‘ 1ë¡œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”!
        self.W = Parameter(torch.ones((out_features, in_features)))
        self.b = Parameter(torch.ones(out_features))

    def forward(self, x):
        output = torch.addmm(self.b, x, self.W.T) # ê³±ì…ˆ + ë§ì…ˆ ë™ì‹œì— ìˆ˜í–‰

        return output


# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
x = torch.Tensor([[1, 2],
                  [3, 4]])

linear = Linear(2, 3)
output = linear(x)


output 
#output == torch.Tensor([[4, 4, 4],
                     # [8, 8, 8]])):
```
- buffer? : ì¼ë°˜ì ì¸ tensorì™€ ë‹¤ë¥´ê²Œ ê°’ì´ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•ŠëŠ”ë‹¤í•´ë„ ì €ì¥í•˜ê³  ì‹¶ì€ Tensorê°€ ìˆì„ë•Œ, bufferì— ë“±ë¡í•˜ë©´ ëª¨ë¸ì„ ì €ì¥í•  ë•Œ, í•´ë‹¹ tensorë“¤ë„ ê°™ì´ ì €ì¥í•  ìˆ˜ ìˆë‹¤.

```python
import torch
from torch import nn
from torch.nn.parameter import Parameter


# TODO : Model ëª¨ë¸ì„ ì™„ì„±í•˜ì„¸ìš”!
class Model(nn.Module):
    def __init__(self):
        super().__init__()

        self.parameter = Parameter(torch.Tensor([7]))
        self.tensor = torch.Tensor([7])

        # TODO : torch.Tensor([7])ë¥¼ bufferì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ bufferì— ë“±ë¡í•´ë³´ì„¸ìš”!
        self.register_buffer('buffer', torch.Tensor([7]), persistent=True)



# ì•„ë˜ ì½”ë“œëŠ” ìˆ˜ì •í•˜ì‹¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!
model = Model()

try:
    buffer = model.get_buffer('buffer')
    if buffer == 7:
        print("ğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ!!! ğŸ‰ğŸ‰ğŸ‰\n")
        print("ğŸ‰ ì´ì œ bufferì— ë“±ë¡ëœ tensorëŠ” ëª¨ë¸ì´ ì €ì¥ë  ë•Œ ê°™ì´ ì €ì¥ë ê±°ì˜ˆìš”! ğŸ‰")
        print(model.state_dict())
    else:
        print("ë‹¤ì‹œ ë„ì „í•´ë´ìš”!")
except:
    print("ë‹¤ì‹œ ë„ì „í•´ë´ìš”!"
```

### Tensor vs Parameter vs Buffer

- "Tensor"
    - âŒ gradient ê³„ì‚°
    - âŒ ê°’ ì—…ë°ì´íŠ¸
    - âŒ ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥
- "Parameter"
    - âœ… gradient ê³„ì‚°
    - âœ… ê°’ ì—…ë°ì´íŠ¸
    - âœ… ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥
- "Buffer"
    - âŒ gradient ê³„ì‚°
    - âŒ ê°’ ì—…ë°ì´íŠ¸
    - âœ… ëª¨ë¸ ì €ì¥ì‹œ ê°’ ì €ì¥


> # ë¶€ê°€í•™ìŠµ

## ë‹¤ì°¨ì› ë°°ì—´?
|   ì´ë¦„ | ì°¨ì›  | í‘œê¸°  |
|---|---|---|
| ìŠ¤ì¹¼ë¼  | 0  | 1  |
|  ë²¡í„° |   1|  [1,2,3] |
| í–‰ë ¬  |  2 |  [[1,2],[3,4]] |
|  í…ì„œ |  ì„ì˜ | [[.....[1,2],[3,4]].....]  |

![ì°¸ê³ ì´ë¯¸ì§€](./img_1/%EC%BA%A1%EC%B2%98.PNG)


## iter tools(cartesian prod_)
- ì£¼ì–´ì§„ í–‰ë ¬ í˜¹ì€ ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“œ ê²½ìš°ì˜ ìˆ˜ë¥¼ ì¶œë ¥í•œë‹¤.

```python
import itertools
a = [1, 2]
b = [4, 5]
list(itertools.product(a,b))


import torch
tensor_a = torch.tensor(a)
tensor_b = torch.tensor(b)
torch.cartesian_prod(tensor_a, tensor_b) # ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ ë‹¤ ì¶œë ¥

```

## Torch autograd(ë¯¸ë¶„)

- ì˜ˆì‹œ1
$$
y = w^2 \\ 
z = 10*y + 50 \\
z = 10*w^2 + 50 
$$

```python
w = torch.tensor(2.0, requires_grad = True) # Trueì´ë©´ ë¯¸ë¶„ì„ í•˜ê² ë‹¤ëŠ” ë§ì„.
y = w ** 2
z = 10 * y + 50
z.backward() #ì—­ì „íŒŒ
w.grad 

```

- ì˜ˆì‹œ2
$$ Q = 3a^3 - b^2  $$
```python

a = torch.tensor([2., 3.], requires_grad = True) # ë¯¸ë¶„ì„ í• ì§€ ì•ˆí• ì§€
b = torch.tensor([6., 4.], requires_grad=True)
Q = 3* a **3 - b**2
external_grad = torch.tensor([1., 1.])
Q.backward(gradient=external_grad)

a.grad   

# aì—ëŒ€í•œ í¸ë¯¸ë¶„ì„ ì‹¤ì‹œí•˜ë©´ ë‹¤ë¥¸ ë³€ìˆ˜(ì´ ì‹ì—ì„œëŠ” b)ëŠ” ìƒìˆ˜ ì·¨ê¸‰í•œë‹¤ ë”°ë¼ì„œ ë‚¨ê²Œë˜ëŠ” ê²°ê³¼ëŠ” 9a^2 ì´ë¯€ë¡œ 
36(a=2),81(a=3)ì´ ëœë‹¤.
```